#!/usr/bin/env python

from __future__ import print_function

from keras.models import Sequential
from keras.layers import Conv2D, Dense, Flatten, MaxPooling2D
from keras.optimizers import RMSprop
from keras.preprocessing.image import ImageDataGenerator
import os
import sys
import json
import traceback

prefix = '/opt/ml/'
input_data_path = os.path.join(prefix, 'input', 'data', 'training')
output_path = os.path.join(prefix, 'output')
model_path = os.path.join(prefix, 'model')
param_path = os.path.join(prefix, 'input/config/hyperparameters.json')

def define_model(params):
    model = Sequential()
    model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(150, 150, 3)))
    model.add(MaxPooling2D(pool_size=(2,2)))
    model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2,2)))
    model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2,2)))
    model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2,2)))
    model.add(Flatten())
    model.add(Dense(512, activation='relu'))
    model.add(Dense(1, activation='sigmoid'))

    model.compile(optimizer=RMSprop(lr=1e-4), loss='binary_crossentropy', metrics=['accuracy'])

    print(model.summary())

    return model

def get_generators(params):
    train_dir = os.path.join(input_data_path, 'train')
    validation_dir = os.path.join(input_data_path, 'validation')

    train_gen = ImageDataGenerator(rescale=1./255)
    test_gen = ImageDataGenerator(rescale=1./255)

    batch_size = params.get('batch_size', 20)

    train_generator = train_gen.flow_from_directory(train_dir,
                                                    target_size=(150, 150),
                                                    batch_size=batch_size,
                                                    class_mode='binary')
    validation_generator = test_gen.flow_from_directory(validation_dir,
                                                    target_size=(150, 150),
                                                    batch_size=batch_size,
                                                    class_mode='binary')

    print('Class indices:', train_generator.class_indices)
    print('Class names:', train_generator.classes)

    return train_generator, validation_generator

def train():
    print('Start training')
    try:
        training_params = {}
        with open(param_path, 'r') as p:
            training_params = json.load(p)

        model = define_model(training_params)
        epochs = training_params.get('epochs', 30)
        batch_size = training_params.get('batch_size', 20)
        train_samples = 2000
        validation_samples = 1000

        train_generator, validation_generator = get_generators(training_params)
        history = model.fit_generator(
            train_generator,
            steps_per_epoch=train_samples//batch_size,
            epochs=epochs,
            validation_data=validation_generator,
            validation_steps=validation_samples//batch_size
        )
        model.save(os.path.join(model_path, 'kaggle_dogs_cats.h5'))
        print('Training complete. Results: ', history.history)
        sys.exit(0)

    except Exception as e:
        trace = traceback.format_exc()
        with open(os.path.join(output_path, 'failure'), 'w') as s:
            s.write('Exception during training: ' + str(e) + '\n' + trace)

        print('Exception during training: ' + str(e) + '\n' + trace, file=sys.stderr)
        sys.exit(255)

if __name__ == '__main__':
    train()
